# -*- coding: utf-8 -*-
"""COLA - di Riceche correlate, domande e serp

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GNF8dp59RPmlKdnwxndyTB1mixsUck4i
"""

import csv
import requests
import json
import pandas as pd
import numpy as np
import time
from google.colab import files

#Upload file from google.colab import files
uploaded = files.upload()
filename = next(iter(uploaded))

# Caricare il csv
df = pd.read_csv(filename)

print(df)
time. sleep(5)

# Api key e url 
api_key = "8DF7FB8EEF7A40F29D943213BC388267"
 # 3 parte url
url_finale = 'location=Metropolitan+City+of+Rome%3CLazio%3CItaly&google_domain=google.it&gl=it&hl=it&include_answer_box=true'

#Tempo
start = time.time()

# Crea un DataFrame per memorizzare i risultati
results = pd.DataFrame()
frasi = df[['Main phrase1','Main phrase2', 'Main phrase3', 'Main phrase4']]
# Itera su ogni riga del DataFrame
for index, row in df.iterrows():
    H1 = row['H1']
    URL = row['URL']
    syncon = row['syncon1']
    lemma = row['Lemma1']
    frase1 = row['Main phrase1'] 
    frase2 = row['Main phrase2']
    frase3 = row['Main phrase3'] 
    frase4 = row['Main phrase4']
    keyword1 = syncon + " " + lemma + " " + frase1
    keyword2 = syncon + " " + lemma + " " + frase2
    keyword3 = syncon + " " + lemma + " " + frase3
    keyword4 = syncon + " " + lemma + " " + frase4

    url1 = f'https://api.valueserp.com/search?api_key={api_key}&q={keyword1}&{url_finale}'
    time.sleep(1)
    url2 = f'https://api.valueserp.com/search?api_key={api_key}&q={keyword2}&{url_finale}'
    time.sleep(1)
    url3 = f'https://api.valueserp.com/search?api_key={api_key}&q={keyword3}&{url_finale}'
    time.sleep(1)
    url4 = f'https://api.valueserp.com/search?api_key={api_key}&q={keyword4}&{url_finale}'
    

    # Effettua la richiesta all'endpoint
    response1 = requests.get(url1)
    response2 = requests.get(url2)
    response3 = requests.get(url3)
    response4 = requests.get(url4)

    # Carica il risultato come un dizionario Python 
    data1 = response1.json()
    data2 = response2.json()
    data3 = response3.json()
    data4 = response4.json()
    
    # Estrai le related_questions e le related_searches dal risultato
   
    related_questions1 = data1.get('related_questions', [])
    related_searches1 = data1.get('related_searches', [])
    organic_results1 = data1.get('organic_results', [])

    related_questions2 = data2.get('related_questions', [])
    related_searches2 = data2.get('related_searches', [])
    organic_results2 = data2.get('organic_results', [])

    related_questions3 = data3.get('related_questions', [])
    related_searches3 = data3.get('related_searches', [])
    organic_results3 = data3.get('organic_results', [])

    related_questions4 = data4.get('related_questions', [])
    related_searches4 = data4.get('related_searches', [])
    organic_results4 = data4.get('organic_results', [])
    
    # Frase1
    for question in related_questions1:        
        question1 = question['question']
        if question1 != "":
            results = results.append({'H1': H1 ,'keyword': keyword1, 'query': np.nan, 'question': question1,'title': np.nan,'domain': np.nan, 'link':np.nan }, ignore_index=True)
        else:
            results = results.append({'H1': H1 ,'keyword': keyword1, 'query': np.nan, 'question': np.nan,'title': np.nan,'domain': np.nan, 'link':np.nan  }, ignore_index=True)

    
    for search in related_searches1:
        search1 = search['query']
        if search1 != "":
            results = results.append({'H1': H1,'keyword': keyword1,'query': search1, 'question': np.nan ,'title': np.nan,'domain': np.nan, 'link':np.nan},ignore_index=True)
        else:
            results = results.append({'H1': H1 ,'keyword': keyword1, 'query': np.nan, 'question': np.nan,'title': np.nan,'domain': np.nan, 'link':np.nan  }, ignore_index=True)
    
     # Itera sui primi 3 organic_results
    for item in organic_results1[:3]:

        # Estrai title, domain e link dai risultati organici
        title = item['title']
        domain = item['domain']
        link = item['link']
        results = results.append({ 'H1': H1 ,'keyword': keyword1,'query': np.nan, 'question': np.nan, 'title':title,'domain':domain, 'link':link}, ignore_index=True)
        
    # Frase2
    for question in related_questions2:
        question2 = question['question']
        if question2 != "":
            results = results.append({'H1': H1 ,'keyword': keyword2, 'query': np.nan, 'question': question2,'title': np.nan,'domain': np.nan, 'link':np.nan  }, ignore_index=True)
        else:
            results = results.append({'H1': H1 ,'keyword': keyword2, 'query': np.nan, 'question': np.nan ,'title': np.nan,'domain': np.nan, 'link':np.nan }, ignore_index=True)
    
    for search in related_searches2:
        search2 = search['query']
        if search2 != "":
            results = results.append({'H1': H1,'keyword': keyword2,'query': search2, 'question': np.nan,'title': np.nan,'domain': np.nan, 'link':np.nan }, ignore_index=True)
        else:
            results = results.append({'H1': H1 ,'keyword': keyword2, 'query': np.nan, 'question': np.nan,'title': np.nan,'domain': np.nan, 'link':np.nan  }, ignore_index=True)
    
      # Itera sui primi 3 organic_results
    for item in organic_results2[:3]:
        # Estrai title, domain e link dai risultati organici
        title = item['title']
        domain = item['domain']
        link = item['link']
        results = results.append({ 'H1': H1 ,'keyword': keyword2,'query': np.nan, 'question': np.nan, 'title':title,'domain':domain, 'link':link}, ignore_index=True)

    # Frase3
    for question in related_questions3:
        question2 = question['question']
        if question3 != "":
            results = results.append({'H1': H1 ,'keyword': keyword3, 'query': np.nan, 'question': question2,'title': np.nan,'domain': np.nan, 'link':np.nan  }, ignore_index=True)
        else:
            results = results.append({'H1': H1 ,'keyword': keyword3, 'query': np.nan, 'question': np.nan ,'title': np.nan,'domain': np.nan, 'link':np.nan }, ignore_index=True)
    
    for search in related_searches3:
        search3 = search['query']
        if search3 != "":
            results = results.append({'H1': H1,'keyword': keyword3,'query': search3, 'question': np.nan,'title': np.nan,'domain': np.nan, 'link':np.nan }, ignore_index=True)
        else:
            results = results.append({'H1': H1 ,'keyword': keyword3, 'query': np.nan, 'question': np.nan,'title': np.nan,'domain': np.nan, 'link':np.nan  }, ignore_index=True)
    
      # Itera sui primi 3 organic_results
    for item in organic_results3[:3]:
        # Estrai title, domain e link dai risultati organici
        title = item['title']
        domain = item['domain']
        link = item['link']
        results = results.append({ 'H1': H1 ,'keyword': keyword3,'query': np.nan, 'question': np.nan, 'title':title,'domain':domain, 'link':link}, ignore_index=True)


       # Frase4
    for question in related_questions4:
        question4 = question['question']
        if question4 != "":
            results = results.append({'H1': H1 ,'keyword': keyword4, 'query': np.nan, 'question': question2,'title': np.nan,'domain': np.nan, 'link':np.nan  }, ignore_index=True)
        else:
            results = results.append({'H1': H1 ,'keyword': keyword4, 'query': np.nan, 'question': np.nan ,'title': np.nan,'domain': np.nan, 'link':np.nan }, ignore_index=True)
    
    for search in related_searches4:
        search4 = search['query']
        if search4 != "":
            results = results.append({'H1': H1,'keyword': keyword4,'query': search4, 'question': np.nan,'title': np.nan,'domain': np.nan, 'link':np.nan }, ignore_index=True)
        else:
            results = results.append({'H1': H1 ,'keyword': keyword4, 'query': np.nan, 'question': np.nan ,'title': np.nan,'domain': np.nan, 'link':np.nan }, ignore_index=True)

       # Itera sui primi 3 organic_results
    for item in organic_results4[:3]:
        # Estrai title, domain e link dai risultati organici
        title = item['title']
        domain = item['domain']
        link = item['link']
        results = results.append({ 'H1': H1 ,'keyword': keyword4,'query': np.nan, 'question': np.nan, 'title':title,'domain':domain, 'link':link}, ignore_index=True)
    # Salva il DataFrame dei risultati in un file CSV
       # Salva il DataFrame dei risultati in un file CSV
    filename = (H1 + '.csv')
    results.to_csv(H1 + '.csv', index=False)
    #Download
    files.download(filename)



# Stampa i risultati
print(results)

end = time.time()
print(end - start)

# results = pd.DataFrame()
# frasi = df[['Main phrase1','Main phrase3']]
# Itera su ogni riga del DataFrame
# for index, row in df.iterrows():
#     H1 = row['H1']
#     URL = row['URL']
#     syncon = row['Syncon']
#     frase1 = row['Main phrase1'] 
#     frase3 = row['Main phrase3']
#     keyword1 = syncon + " " + frase1
#     keyword3 = syncon +  " " + frase3 
#     print(keyword1)
#     print(keyword3)

#la logica dietro diocaro

# for index, row in df.iterrows():
#     H1 = row['H1']
#     URL = row['URL']
#     syncon = row['Syncon']
#     frase1 = syncon + " " + row['Main phrase1'] 
#     frase3 = syncon + " " + row['Main phrase3']
#     print(frase1)
#     print(frase3)

# Salva il DataFrame dei risultati in un file CSV
filename = (H1 + '.csv')
results.to_csv(H1 + '.csv', index=False)
    #Download
files.download(filename)

# Salva il DataFrame dei risultati in un file CSV
results.to_csv('results.csv', index=False)

#Download

files.download("results.csv")